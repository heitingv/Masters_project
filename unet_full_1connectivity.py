# -*- coding: utf-8 -*-
"""unet_full_1connectivity.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15ni8_FjO5Y25oOr0MTLYuSKyIhOAW6vl
"""

!pip install pydicom
!pip install barbar

from google.colab import drive
drive.mount('/gdrive')

import os
import matplotlib
import numpy as np
import cv2
import matplotlib.pyplot as plt
import pydicom
from tqdm import tqdm_notebook as tqdm
import random
import time
from barbar import Bar 
import progressbar

import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.autograd import Variable
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torch.utils.data import Dataset as BaseDataset
from tqdm import trange
from time import sleep
from torch.utils.data.sampler import SubsetRandomSampler 
use_gpu = torch.cuda.is_available()

class Dataset(BaseDataset):

    CLASSES = ['non tumor','tumor']

    def __init__(self, images_dir, masks_dir, classes=None):
        self.ids_f=[]
        self.ids_m_f=[]
        self.ids = os.listdir(images_dir)
        self.ids_m = os.listdir(masks_dir)
        for i in range(len(self.ids)):
          self.ids[i]=self.ids[i].rstrip(".dcm")
          for i in range(len(self.ids_m)):
            self.ids_m[i]=self.ids_m[i].rstrip(".png")

        for temp in self.ids_m:
          if temp in self.ids:
            self.ids_f.append(temp+'.dcm')
            self.ids_m_f.append(temp+'.png')

        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids_f]
        self.masks_fps = [os.path.join(masks_dir, mask_id) for mask_id in self.ids_m_f]
        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]
    
    def __len__(self):
        return len(self.ids_f)
    
    def breast_left_or_right(self, image_array):
      position=None
      image=(image_array>0).float() #transform image into binary for easier analysis
      coordinates_breast_tissue=(image==1).nonzero() #look at coordinatex where there is '1'
      min_coordinates=torch.min(coordinates_breast_tissue,0)[0][1].item() #find the minimum column of where breast, if breast on the left then 0/1, if right then high number
      
      if  min_coordinates==0 or  min_coordinates==1:
        position='left'
      else:
        position='right'
      
      return(position)

    def image_padding(self, position, image_array, mask_array):

      if image_array.shape[0]==4084:
        if position=='left':
          image_tensor=torch.nn.functional.pad(image_array, (0,(3500-3328),0,(4250-4084)))
          mask_tensor=torch.nn.functional.pad(mask_array, (0,(3500-3328),0,(4250-4084)))
        else:
          image_tensor=torch.nn.functional.pad(image_array, ((3500-3328),0,0,(4250-4084)))
          mask_tensor=torch.nn.functional.pad(mask_array, ((3500-3328),0,0,(4250-4084)))
      
      else:
        if position=='left':
          image_tensor=torch.nn.functional.pad(image_array, (0,(2750-2560),0,(3500-3328)))
          mask_tensor=torch.nn.functional.pad(mask_array, (0,(2750-2560),0,(3500-3328)))
        else:
          image_tensor=torch.nn.functional.pad(image_array, ((2750-2560),0,0,(3500-3328)))
          mask_tensor=torch.nn.functional.pad(mask_array, ((2750-2560),0,0,(3500-3328)))
      
      return(image_tensor,mask_tensor)


    def __getitem__(self, i):
        
        # read data
        image = pydicom.dcmread(self.images_fps[i])
        image = image.pixel_array.astype('float')
        image = torch.from_numpy(image)
      
        mask = cv2.imread(self.masks_fps[i])
        mask = torch.from_numpy(mask)
        mask=mask.long()
        mask=abs((mask.sum(2)/3)-1)
        mask = (mask>0).float()

        position=self.breast_left_or_right(image)
        image_pad, mask_pad = self.image_padding(position,image,mask)
        
        return image_pad, mask_pad

class Dataset_with_NonMass(BaseDataset): #original data non padded or changed in size 

    CLASSES = ['non tumor','tumor']

    def __init__(self, images_dir, masks_dir, classes=None):
        self.ids_f=[]
        self.ids_m_f=[]
        self.ids = os.listdir(images_dir)
        self.ids_m = os.listdir(masks_dir)
        self.images_fps=[]
        self.masks_fps=[]
        for i in range(len(self.ids)):
          self.ids[i]=self.ids[i].rstrip(".dcm")
          for i in range(len(self.ids_m)):
            self.ids_m[i]=self.ids_m[i].rstrip(".png")

        for i in range(len(self.ids)):
          temp=self.ids[i][0:8]
          if temp in self.ids_m:
            self.ids_f.append(self.ids[i]+'.dcm')
            self.ids_m_f.append(temp+'.png')

        for i in range(len(self.ids_m_f)):
          mask_id=self.ids_m_f[i]
          image_id=self.ids_f[i]
          temp=os.path.join(masks_dir, mask_id)
          presence=self.test_mass(temp)

          if presence==False:
            self.images_fps.append(os.path.join(images_dir, image_id))
            self.masks_fps.append(os.path.join(masks_dir, mask_id))

          temp=None
          mask_id=None
          image_id=None

        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]

    def test_mass(self,name):
      presence=None

      mask = cv2.imread(name)
      mask = torch.from_numpy(mask)
      mask=mask.long()
      mask=abs((mask.sum(2)/3)-1)
      mask = (mask>0).float()

      if 1 in mask:
        presence=True
      else:
        presence=False

      return(presence)

    def __len__(self):
        return len(self.images_fps)

    def breast_left_or_right(self, image_array):
      position=None
      image=(image_array>0).float() #transform image into binary for easier analysis
      coordinates_breast_tissue=(image==1).nonzero() #look at coordinatex where there is '1'
      min_coordinates=torch.min(coordinates_breast_tissue,0)[0][1].item() #find the minimum column of where breast, if breast on the left then 0/1, if right then high number
      
      if  min_coordinates==0 or  min_coordinates==1:
        position='left'
      else:
        position='right'
      
      return(position)

    def image_padding(self, position, image_array, mask_array):

      if image_array.shape[0]==4084:
        if position=='left':
          image_tensor=torch.nn.functional.pad(image_array, (0,(3500-3328),0,(4250-4084)))
          mask_tensor=torch.nn.functional.pad(mask_array, (0,(3500-3328),0,(4250-4084)))
        else:
          image_tensor=torch.nn.functional.pad(image_array, ((3500-3328),0,0,(4250-4084)))
          mask_tensor=torch.nn.functional.pad(mask_array, ((3500-3328),0,0,(4250-4084)))
      
      else:
        if position=='left':
          image_tensor=torch.nn.functional.pad(image_array, (0,(2750-2560),0,(3500-3328)))
          mask_tensor=torch.nn.functional.pad(mask_array, (0,(2750-2560),0,(3500-3328)))
        else:
          image_tensor=torch.nn.functional.pad(image_array, ((2750-2560),0,0,(3500-3328)))
          mask_tensor=torch.nn.functional.pad(mask_array, ((2750-2560),0,0,(3500-3328)))
      
      return(image_tensor,mask_tensor)

    def __getitem__(self, i):
        
        # read data
        image = pydicom.dcmread(self.images_fps[i])
        image = image.pixel_array.astype('float')
        image = torch.from_numpy(image)
      
        mask = cv2.imread(self.masks_fps[i])
        mask = torch.from_numpy(mask)
        mask = mask.long()
        mask = abs((mask.sum(2)/3)-1)
        mask = (mask>0).float()

        position=self.breast_left_or_right(image)
        image_pad, mask_pad = self.image_padding(position,image,mask)

        return image_pad, mask_pad

class Patch_Extraction_250_by_250:

  CLASSES = ['non tumor','tumor']


  def __init__(self, image_tensor, mask_tensor, image_number, classes=None, l_connectivity=None): #images and masks already padded
        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]
        self.image_tensor=image_tensor
        self.mask_tensor=mask_tensor
        self.image_number=image_number
        self.l_connectivity=l_connectivity

  def breast_left_or_right(self):
      position=None
      image=(self.image_tensor>0).float() #transform image into binary for easier analysis
      coordinates_breast_tissue=(image==1).nonzero() #look at coordinatex where there is '1'
      min_coordinates=torch.min(coordinates_breast_tissue,0)[0][1].item() #find the minimum column of where breast, if breast on the left then 0/1, if right then high number
      
      if  min_coordinates==0 or  min_coordinates==1:
        position='left'
      else:
        position='right'
      
      return(position)

  def find_coordinates(self,mask_patches):
      coordinate=[]
      position=self.breast_left_or_right()
      connectivity=self.l_connectivity

      left_array_154=[]
      right_array_154=[]
      left_array_238=[]
      right_array_238=[]

      if mask_patches.size()[0]==154:
        width=11
      else:
        width=14

      for i in range(14):
        for j in range(connectivity):
          left_array_154.append(j+11*i)

      for i in range(14):
        for j in range(connectivity):
          right_array_154.append((11-j-1)+11*i)

      for i in range(17):
        for j in range(connectivity):
          left_array_238.append(j+14*i)

      for i in range(17):
        for j in range(connectivity):
          right_array_238.append((14-j-1)+14*i)

      for j in range(mask_patches.size()[0]):
        if 1 in mask_patches[j]:
          coordinate.append(j)
          for i in range(connectivity):
            coordinate.append(j-(i+1)) #left
            coordinate.append(j+(i+1)) #right
            coordinate.append(j-(i+1)*width) #up
            coordinate.append(j+(i+1)*width) #down
            coordinate.append((j-(i+1)*width)-1) #up-left=>digaonal above left
            coordinate.append((j-(i+1)*width)+1) #up-right=>digaonal above right
            coordinate.append((j+(i+1)*width)-1) #down-left=>digaonal below left
            coordinate.append((j+(i+1)*width)+1) #down-right=>digaonal below right

      coordinate=list(set(coordinate))
      coordinate=[i for i in coordinate if i >=0]
      coordinate=[i for i in coordinate if i <=mask_patches.size()[0]]

      if position=='left' and mask_patches.size()[0]==154:
        coordinate= [i for i in coordinate if i not in right_array_154]
      
      elif position=='right' and mask_patches.size()[0]==154:
        coordinate= [i for i in coordinate if i not in left_array_154]

      elif position=='left' and mask_patches.size()[0]==238:
        coordinate= [i for i in coordinate if i not in right_array_238]
      
      else:
        coordinate= [i for i in coordinate if i not in left_array_238]
      
      coordinate.sort()

      return (coordinate) 

  def get_patches(self): #only patches that have tumour present
        h, w =self.image_tensor.size()
        nrows=250
        ncols=250

        image_patches=self.image_tensor.numpy()
        image_patches=image_patches.reshape(h//nrows, nrows, -1, ncols).swapaxes(1,2).reshape(-1, nrows, ncols)
        image_patches=torch.from_numpy(image_patches)
        # image_patches=image_patches.numpy()

        mask_patches=self.mask_tensor.numpy()
        mask_patches=mask_patches.reshape(h//nrows, nrows, -1, ncols).swapaxes(1,2).reshape(-1, nrows, ncols)
        mask_patches=torch.from_numpy(mask_patches)
        # mask_patches=mask_patches.numpy()

        return (image_patches, mask_patches)

# full_dataset = Dataset('/gdrive/My Drive/mass','/gdrive/My Drive/mask', classes=['non tumor','tumor'])
# num_train=len(full_dataset)

# size_train= int(np.ceil(0.6* num_train))
# size_val= int(np.floor(0.2* num_train))
# size_test= int(np.floor(0.2* num_train))

# train_set, val_set, test_set = torch.utils.data.random_split(full_dataset, [size_train, size_val, size_test])

# dataset_NonMass = Dataset_with_NonMass('/gdrive/My Drive/AllDICOMs','/gdrive/My Drive/total', classes=['non tumor','tumor'] )

# #need same amount for training mass & non mass
# nb_NonMass_images_trained=int(np.ceil(size_train)) #add non mass images 
# nb_NonMass_images_validation=int(np.ceil(0.3*(size_val))) #add 30% more images that don't have mass
# nb_NonMass_images_tested=int(np.ceil(0.3*(size_test))) #add 30% more images that don't have mass

# NonMass_set_train,NonMass_set_val,NonMass_set_test, unwanted_set = torch.utils.data.random_split(dataset_NonMass, [nb_NonMass_images_trained,nb_NonMass_images_validation,nb_NonMass_images_tested,len(dataset_NonMass)-(nb_NonMass_images_trained+nb_NonMass_images_validation+nb_NonMass_images_tested)])
# full_train_loader = torch.utils.data.ConcatDataset([train_set,NonMass_set_train])
# full_val_loader = torch.utils.data.ConcatDataset([val_set,NonMass_set_val])
# full_test_loader = torch.utils.data.ConcatDataset([test_set,NonMass_set_test])

# train_loader = torch.utils.data.DataLoader(full_train_loader,shuffle=True,batch_size=1)
# val_loader = torch.utils.data.DataLoader(full_val_loader,shuffle=True,batch_size=1)
# test_loader = torch.utils.data.DataLoader(full_test_loader,shuffle=True,batch_size=1)

# torch.save(test_loader, '/gdrive/My Drive/test_loader_full_1connect.pth') 
# torch.save(train_loader, '/gdrive/My Drive/train_loader_full_1connect.pth') 
# torch.save(val_loader, '/gdrive/My Drive/val_loader_full_1connect.pth')

test_loader=(torch.load('/gdrive/My Drive/test_loader_full_1connect.pth'))
train_loader=(torch.load('/gdrive/My Drive/train_loader_full_1connect.pth'))
val_loader=(torch.load('/gdrive/My Drive/val_loader_full_1connect.pth'))

class DoubleConv(nn.Module):
    """(convolution => [BN] => ReLU) * 2"""

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.double_conv(x)


class Down(nn.Module):
    """Downscaling with maxpool then double conv"""

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.maxpool_conv = nn.Sequential(
            nn.MaxPool2d(2),
            DoubleConv(in_channels, out_channels)
        )

    def forward(self, x):
        return self.maxpool_conv(x)


class Up(nn.Module):
    """Upscaling then double conv"""

    def __init__(self, in_channels, out_channels, bilinear=True):
        super().__init__()

        # if bilinear, use the normal convolutions to reduce the number of channels
        if bilinear:
            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
        else:
            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)

        self.conv = DoubleConv(in_channels, out_channels)

    def forward(self, x1, x2):
        x1 = self.up(x1)
        # input is CHW
        diffY = torch.tensor([x2.size()[2] - x1.size()[2]])
        diffX = torch.tensor([x2.size()[3] - x1.size()[3]])

        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,
                        diffY // 2, diffY - diffY // 2])
        # if you have padding issues, see
        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a
        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd
        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)


class OutConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(OutConv, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)

    def forward(self, x):
        return self.conv(x)

class UNet(nn.Module):
    def __init__(self, n_channels, n_classes, bilinear=True):
        super(UNet, self).__init__()
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.bilinear = bilinear

        self.inc = DoubleConv(n_channels, 64)
        self.down1 = Down(64, 128)
        self.down2 = Down(128, 256)
        self.down3 = Down(256, 512)
        self.down4 = Down(512, 512)
        self.up1 = Up(1024, 256, bilinear)
        self.up2 = Up(512, 128, bilinear)
        self.up3 = Up(256, 64, bilinear)
        self.up4 = Up(128, 64, bilinear)
        self.outc = OutConv(64, n_classes)

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)
        x = self.up1(x5, x4)
        x = self.up2(x, x3)
        x = self.up3(x, x2)
        x = self.up4(x, x1)
        logits = self.outc(x)
        return logits

unet = UNet(n_classes=2, n_channels=1)

import torch.optim as optim

criterion = nn.CrossEntropyLoss() 
optimizer = optim.SGD(unet.parameters(), lr=0.001, momentum=0.9)

def iou(predicted,truth): #truth=mask and predicted=outputs_final
    # But if you are passing output from UNet or something it will most probably
    # be with the BATCH x 1 x H x W shape
  
    overlap_tumour = (truth*predicted).sum()  # Will be zero if Truth=0 or Prediction=0
    union_tumour = (predicted+truth)
    union_tumour = (union_tumour>0).float()        #transform numbers >1 to 1
    union_tumour = union_tumour.sum()
    
    if overlap_tumour==0 or union_tumour==0:
      iou_tumour=0
    else:
      iou_tumour = overlap_tumour / union_tumour

    truth_b=abs(truth-1)
    predicted_b=abs(predicted-1)    
    overlap_background = (truth_b*predicted_b).sum()  # Will be zero if Truth=0 or Prediction=0
    union_background = (predicted_b+truth_b)
    union_background = (union_background>0).float()
    union_background = union_background.sum()
   
    if overlap_background==0 or union_background==0:
      iou_background=0
    else:
      iou_background = overlap_background / union_background
   
    iou_background = (overlap_background + 0.00000001) / (union_background + 0.00000001)

    #thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10  # This is equal to comparing with thresolds
    
    iou_t=(iou_tumour+iou_background)/2

    iou=iou_t.item()

    return iou

running_loss = 0.0
epochs=5
val_loss = 0.0
best_loss=271.4073999990361
iou_loss = 0.0
val_iou_loss = 0.0
counter=0
nb_patches_analyzed=0
nb_patches_analyzed_v=0

model=unet
model.load_state_dict(torch.load('/gdrive/My Drive/unet_full_1connect.pth'))

time.sleep(5)
for epoch in range(epochs):  # loop over the dataset multiple times

    time.sleep(5)
    Bar = progressbar.ProgressBar(max_value=len(train_loader))
    #train 
    for i, data in enumerate(Bar(train_loader), 0):
        image, mask = data

        patch_extract = Patch_Extraction_250_by_250(image.squeeze(), mask.squeeze(), i, classes=['non tumor','tumor'],l_connectivity=2 )
        (image_patches,mask_patches)=patch_extract.get_patches() 
        coordinate_array=patch_extract.find_coordinates(mask_patches)

        print_patch_tum=0
        
        for j in range(len(coordinate_array)):
          temp=coordinate_array[j]

          image_p=(image_patches[temp].unsqueeze(dim=0)).unsqueeze(dim=0) #need to unsqueeze to put into unet for image_patch=[1,1,height_size_patch, width_size_patch]
          mask_p=mask_patches[temp].unsqueeze(dim=0)

          # zero the parameter gradients
          optimizer.zero_grad()

          # forward + backward + optimize
          outputs = model(image_p.float()) #forward propagation # outputs = [batch_size, nb_class=2, H=256, W=256]
          outputs_final_probabilities, outputs_final = torch.max(outputs.squeeze(), axis=0) #takes the maximum probability either background or tumour
          loss = criterion(outputs.float(), mask_p.long())
          loss.backward() #backward propagation
          optimizer.step() #optimize
          running_loss += loss.item()
          iou_loss += iou(outputs_final,mask_p.squeeze()) #look at the loss info cad correct or not between predicted output and real class/label

          if (print_patch_tum==0) and (1 in mask_p):
            image_p_t=image_p
            mask_p_t=mask_p
            outputs_final_t=outputs_final
          
        nb_patches_analyzed+=len(coordinate_array)

    time.sleep(5)
    BarTwo = progressbar.ProgressBar(max_value=len(val_loader))
    #validation     
    for i, data_v in enumerate(BarTwo(val_loader), 0):
        image_v, mask_v = data_v
        patch_extract = Patch_Extraction_250_by_250(image_v.squeeze(), mask_v.squeeze(), i, classes=['non tumor','tumor'],l_connectivity=2 )
        (image_patches_v,mask_patches_v)=patch_extract.get_patches() 
        coordinate_array_v=patch_extract.find_coordinates(mask_patches_v)

        for j in range(len(coordinate_array_v)):
          temp_v=coordinate_array_v[j]

          image_p_v=(image_patches_v[temp_v].unsqueeze(dim=0)).unsqueeze(dim=0) #need to unsqueeze to put into unet for image_patch=[1,1,height_size_patch, width_size_patch]
          mask_p_v=mask_patches_v[temp_v].unsqueeze(dim=0)
          outputs_v=model(image_p_v.float())
          
          outputs_final_probabilities_v, outputs_final_v = torch.max(outputs_v.squeeze(), axis=0)
          loss_v = criterion(outputs_v.float(),mask_p_v.long()) #why in loop because won't change loss 
          val_loss += loss_v.item()
          val_iou_loss += iou(outputs_final_v, mask_p_v.squeeze()) #look at the loss info cad correct or not between predicted output and real class/label
        
        nb_patches_analyzed_v+=len(coordinate_array_v)

    #save best model
    if val_iou_loss > best_loss:
      best_loss=val_iou_loss
      torch.save(unet.state_dict(),'/gdrive/My Drive/unet_full_1connect.pth')
      print('\nbest_loss:', best_loss)
    
    #print for each epoch #print iou in training and validation #need to change 10 and 5 if changed above
    print('Epoch %d : train loss: %.3f' % (epoch + 1 +1 , running_loss / (nb_patches_analyzed)),'; val loss: %.3f' % (val_loss / (nb_patches_analyzed_v)))
    print('Epoch %d :iou train loss: %.3f' % (epoch + 1+1 , iou_loss/ (nb_patches_analyzed)),'; iou val loss: %.3f' % (val_iou_loss/ (nb_patches_analyzed_v)),'\n')  

    counter+=1

    if counter==1:
      print('Number of training patches analyzed is:', nb_patches_analyzed)
      print('Number of validation patches analyzed is:', nb_patches_analyzed_v)

    #print for every epoch
    #print for every epoch
    if (counter%1)==0:
      fig = plt.figure()
      plt.subplot(1, 3, 1)
      plt.imshow(image_p_t.squeeze())
      plt.subplot(1, 3, 2)
      plt.imshow(mask_p_t.squeeze())
      plt.subplot(1, 3, 3)
      plt.imshow(outputs_final_t.detach().numpy())
      matplotlib.image.imsave('/gdrive/My Drive/images_report/unet_full_1connect/training/image_patch_epoch_'+str(epoch+1)+'.png',image_p_t.squeeze())
      matplotlib.image.imsave('/gdrive/My Drive/images_report/unet_full_1connect/training/mask_patch_epoch_'+str(epoch+1)+'.png',mask_p_t.squeeze())
      matplotlib.image.imsave('/gdrive/My Drive/images_report/unet_full_1connect/training/prediction_patch_epoch_'+str(epoch+1)+'.png',outputs_final_t.detach().numpy())

    val_loss = 0.0
    running_loss = 0.0
    iou_loss = 0.0
    val_iou_loss = 0.0
    nb_patches_analyzed = 0
    nb_patches_analyzed_v = 0

print('Finished Training')

def re_patch(prediction_array):
  nrows=250
  ncols=250

  if prediction_array.size()[0]==154:
    y=14
    x=11
    initial_x=2750
    initial_y=3500
  else:
    y=17
    x=14
    initial_x=3500
    initial_y=4250

  re_patch_prediction=prediction_array.reshape(y,x,nrows, ncols)
  re_patch_prediction=re_patch_prediction.numpy().swapaxes(2,1)
  re_patch_prediction=torch.from_numpy(re_patch_prediction)
  re_patch_prediction=re_patch_prediction.reshape(initial_y, initial_x)

  return(re_patch_prediction)

model_t=unet
model_t.load_state_dict(torch.load('/gdrive/My Drive/unet_model_1_connecivity.pth'))
test_loss = 0.0
test_iou_loss = 0.0
nb_patches_analyzed_t=0
iou_tumour_list=[]
ground=[]

#time.sleep(2)
#test model

time.sleep(5)
BarTest = progressbar.ProgressBar(max_value=len(test_loader))
for i, data_t in enumerate(BarTest(test_loader), 0):
  time.sleep(2)
  image_t, mask_t = data_t
  
  patch_extract = Patch_Extraction_250_by_250(image_t.squeeze(), mask_t.squeeze(), i, classes=['non tumor','tumor'],l_connectivity=2)
  (image_patches_t,mask_patches_t)=patch_extract.get_patches() 
  outputs_all=torch.zeros(image_patches_t.size()[0],250,250)

  for j in range(len(image_patches_t)):
    image_p_t=(image_patches_t[j].unsqueeze(dim=0)).unsqueeze(dim=0) #need to unsqueeze to put into unet for image_patch=[1,1,height_size_patch, width_size_patch]
    mask_p_t=mask_patches_t[j].unsqueeze(dim=0)
    outputs_t=model_t(image_p_t.float())
    outputs_final_probabilities_t, outputs_final_t = torch.max(outputs_t.squeeze(), axis=0)
    outputs_all[j]=outputs_final_t

  repatched_predication=re_patch(outputs_all)
  iou_single = iou(repatched_predication, mask_padded.squeeze())
  iou_tumour_list.append(iou_tumour(repatched_predication, mask_t.squeeze()))
  test_iou_loss += iou_single 

  if 1 in mask_t:
    ground.append(1)
  else:
    ground.append(0)

  #print for each epoch #print iou in training and validation
  print('\nTest Image %d : iou: %.3f' % (i + 1, iou_single),'\n')  

  fig = plt.figure()
  plt.subplot(1, 3, 1)
  plt.imshow(image_t.squeeze())
  plt.subplot(1, 3, 2)
  plt.imshow(mask_padded)
  plt.subplot(1, 3, 3)
  plt.imshow(repatched_predication.numpy())

print('\nOverall Test Images: iou: %.3f' % (test_iou_loss/ len(test_loader)),'\n')

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

prediction=[]
threshold=0.1
true_positive=[]
false_positive=[]
true_negative=[]
false_negative=[]

# print(ground)
# print(iou_tumour_list)

for i in range(len(iou_tumour_list)):
  if iou_tumour_list[i]<threshold:
    prediction.append(0)
  else:
    prediction.append(1)

fpr, tpr, thresholds = roc_curve(ground, prediction, pos_label=1)

plt.plot(fpr, tpr, color='orange', label='ROC')
plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()
plt.show()