{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of UNet_1connect_full.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO+F1/AV7s8QBBeTqXRxWN1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heitingv/Masters_project/blob/master/Weight_Initialization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHgdpfpiu-XZ",
        "colab_type": "text"
      },
      "source": [
        "Code for Transfer Learning: Weight Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjxxogRwJeU5",
        "colab_type": "text"
      },
      "source": [
        "Install pydicom and barbar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YLvrK0nvd0p",
        "colab_type": "code",
        "outputId": "c3177933-19e9-4044-e836-94934295ffcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip install pydicom\n",
        "!pip install barbar"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydicom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/56/342e1f8ce5afe63bf65c23d0b2c1cd5a05600caad1c211c39725d3a4cc56/pydicom-2.0.0-py3-none-any.whl (35.4MB)\n",
            "\u001b[K     |████████████████████████████████| 35.5MB 89kB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.0.0\n",
            "Collecting barbar\n",
            "  Downloading https://files.pythonhosted.org/packages/48/1f/9b69ce144f484cfa00feb09fa752139658961de6303ea592487738d0b53c/barbar-0.2.1-py3-none-any.whl\n",
            "Installing collected packages: barbar\n",
            "Successfully installed barbar-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOkjJYDaJmEp",
        "colab_type": "text"
      },
      "source": [
        "Link to drive for data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtD_KwZ5vfW-",
        "colab_type": "code",
        "outputId": "10e194d6-c83b-4f14-9f5f-9ddf9123387a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSBBJK2zJpRK",
        "colab_type": "text"
      },
      "source": [
        "Import all libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nQCeu2D_gXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pydicom\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from random import randint\n",
        "\n",
        "import time\n",
        "from barbar import Bar \n",
        "import progressbar\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import auc\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset as BaseDataset\n",
        "from tqdm import trange\n",
        "from time import sleep\n",
        "from torch.utils.data.sampler import SubsetRandomSampler \n",
        "use_gpu = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtd_3-UNKFZ9",
        "colab_type": "text"
      },
      "source": [
        "Class for data only with mass:\n",
        "returns image/mask padded (for patch extraction) and image/mask resized to 250x250"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CG4LUgj-dIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset(BaseDataset):\n",
        "\n",
        "    CLASSES = ['non tumor','tumor']\n",
        "\n",
        "    def __init__(self, images_dir, masks_dir, classes=None):\n",
        "        self.ids_f=[]\n",
        "        self.ids_m_f=[]\n",
        "        self.ids = os.listdir(images_dir)\n",
        "        self.ids_m = os.listdir(masks_dir)\n",
        "        for i in range(len(self.ids)):\n",
        "          self.ids[i]=self.ids[i].rstrip(\".dcm\")\n",
        "          for i in range(len(self.ids_m)):\n",
        "            self.ids_m[i]=self.ids_m[i].rstrip(\".png\")\n",
        "\n",
        "        for temp in self.ids_m:\n",
        "          if temp in self.ids:\n",
        "            self.ids_f.append(temp+'.dcm')\n",
        "            self.ids_m_f.append(temp+'.png')\n",
        "\n",
        "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids_f]\n",
        "        self.masks_fps = [os.path.join(masks_dir, mask_id) for mask_id in self.ids_m_f]\n",
        "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.ids_f)\n",
        "    \n",
        "    def breast_left_or_right(self, image_array):\n",
        "      position=None\n",
        "      image=(image_array>0).float() #transform image into binary for easier analysis\n",
        "      coordinates_breast_tissue=(image==1).nonzero() #look at coordinatex where there is '1'\n",
        "      min_coordinates=torch.min(coordinates_breast_tissue,0)[0][1].item() #find the minimum column of where breast, if breast on the left then 0/1, if right then high number\n",
        "      \n",
        "      if  min_coordinates<=100:\n",
        "        position='left'\n",
        "      else:\n",
        "        position='right'\n",
        "      \n",
        "      return(position)\n",
        "\n",
        "    def image_padding(self, position, image_array, mask_array):\n",
        "\n",
        "      if image_array.shape[0]==4084:\n",
        "        if position=='left':\n",
        "          image_tensor=torch.nn.functional.pad(image_array, (0,(3500-3328),0,(4250-4084)))\n",
        "          mask_tensor=torch.nn.functional.pad(mask_array, (0,(3500-3328),0,(4250-4084)))\n",
        "        else:\n",
        "          image_tensor=torch.nn.functional.pad(image_array, ((3500-3328),0,0,(4250-4084)))\n",
        "          mask_tensor=torch.nn.functional.pad(mask_array, ((3500-3328),0,0,(4250-4084)))\n",
        "      \n",
        "      else:\n",
        "        if position=='left':\n",
        "          image_tensor=torch.nn.functional.pad(image_array, (0,(2750-2560),0,(3500-3328)))\n",
        "          mask_tensor=torch.nn.functional.pad(mask_array, (0,(2750-2560),0,(3500-3328)))\n",
        "        else:\n",
        "          image_tensor=torch.nn.functional.pad(image_array, ((2750-2560),0,0,(3500-3328)))\n",
        "          mask_tensor=torch.nn.functional.pad(mask_array, ((2750-2560),0,0,(3500-3328)))\n",
        "      \n",
        "      return(image_tensor,mask_tensor)\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        \n",
        "        # read data\n",
        "        image = pydicom.dcmread(self.images_fps[i])\n",
        "        image = image.pixel_array.astype('float')\n",
        "        image_re = cv2.resize(image,(250,250))\n",
        "        image = torch.from_numpy(image)\n",
        "      \n",
        "        mask = cv2.imread(self.masks_fps[i])\n",
        "        mask_re = cv2.resize(mask,(250,250))\n",
        "        mask_re = torch.from_numpy(mask_re)\n",
        "        mask_re = mask_re.long()\n",
        "        mask_re = abs((mask_re.sum(2)/3)-1)\n",
        "        mask_re = (mask_re>0).float()\n",
        "        mask = torch.from_numpy(mask)\n",
        "        mask = mask.long()\n",
        "        mask = abs((mask.sum(2)/3)-1)\n",
        "        mask = (mask>0).float()\n",
        "\n",
        "        position=self.breast_left_or_right(image)\n",
        "        image_pad, mask_pad = self.image_padding(position,image,mask)\n",
        "        \n",
        "        return image_pad, mask_pad, image_re, mask_re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I61PCt45KYwL",
        "colab_type": "text"
      },
      "source": [
        "Class for data without mass: returns image/mask padded (for patch extraction) and image/mask resized to 250x250\n",
        "\n",
        "The distinction between the two classes is be able to create a balanced dataset for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj8aXPOZ_jxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset_with_NonMass(BaseDataset): #original data non padded or changed in size \n",
        "\n",
        "    CLASSES = ['non tumor','tumor']\n",
        "\n",
        "    def __init__(self, images_dir, masks_dir, classes=None):\n",
        "        self.ids_f=[]\n",
        "        self.ids_m_f=[]\n",
        "        self.ids = os.listdir(images_dir)\n",
        "        self.ids_m = os.listdir(masks_dir)\n",
        "        self.images_fps=[]\n",
        "        self.masks_fps=[]\n",
        "        for i in range(len(self.ids)):\n",
        "          self.ids[i]=self.ids[i].rstrip(\".dcm\")\n",
        "          for i in range(len(self.ids_m)):\n",
        "            self.ids_m[i]=self.ids_m[i].rstrip(\".png\")\n",
        "\n",
        "        for i in range(len(self.ids)):\n",
        "          temp=self.ids[i][0:8]\n",
        "          if temp in self.ids_m:\n",
        "            self.ids_f.append(self.ids[i]+'.dcm')\n",
        "            self.ids_m_f.append(temp+'.png')\n",
        "\n",
        "        for i in range(len(self.ids_m_f)):\n",
        "          mask_id=self.ids_m_f[i]\n",
        "          image_id=self.ids_f[i]\n",
        "          temp=os.path.join(masks_dir, mask_id)\n",
        "          presence=self.test_mass(temp)\n",
        "\n",
        "          if presence==False:\n",
        "            self.images_fps.append(os.path.join(images_dir, image_id))\n",
        "            self.masks_fps.append(os.path.join(masks_dir, mask_id))\n",
        "\n",
        "          temp=None\n",
        "          mask_id=None\n",
        "          image_id=None\n",
        "\n",
        "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
        "\n",
        "    def test_mass(self,name):\n",
        "      presence=None\n",
        "\n",
        "      mask = cv2.imread(name)\n",
        "      mask = torch.from_numpy(mask)\n",
        "      mask=mask.long()\n",
        "      mask=abs((mask.sum(2)/3)-1)\n",
        "      mask = (mask>0).float()\n",
        "\n",
        "      if 1 in mask:\n",
        "        presence=True\n",
        "      else:\n",
        "        presence=False\n",
        "\n",
        "      return(presence)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images_fps)\n",
        "\n",
        "    def breast_left_or_right(self, image_array):\n",
        "      position=None\n",
        "      image=(image_array>0).float() #transform image into binary for easier analysis\n",
        "      coordinates_breast_tissue=(image==1).nonzero() #look at coordinatex where there is '1'\n",
        "      min_coordinates=torch.min(coordinates_breast_tissue,0)[0][1].item() #find the minimum column of where breast, if breast on the left then 0/1, if right then high number\n",
        "      \n",
        "      if  min_coordinates<=100:\n",
        "        position='left'\n",
        "      else:\n",
        "        position='right'\n",
        "      \n",
        "      return(position)\n",
        "\n",
        "    def image_padding(self, position, image_array, mask_array):\n",
        "\n",
        "      if image_array.shape[0]==4084:\n",
        "        if position=='left':\n",
        "          image_tensor=torch.nn.functional.pad(image_array, (0,(3500-3328),0,(4250-4084)))\n",
        "          mask_tensor=torch.nn.functional.pad(mask_array, (0,(3500-3328),0,(4250-4084)))\n",
        "        else:\n",
        "          image_tensor=torch.nn.functional.pad(image_array, ((3500-3328),0,0,(4250-4084)))\n",
        "          mask_tensor=torch.nn.functional.pad(mask_array, ((3500-3328),0,0,(4250-4084)))\n",
        "      \n",
        "      else:\n",
        "        if position=='left':\n",
        "          image_tensor=torch.nn.functional.pad(image_array, (0,(2750-2560),0,(3500-3328)))\n",
        "          mask_tensor=torch.nn.functional.pad(mask_array, (0,(2750-2560),0,(3500-3328)))\n",
        "        else:\n",
        "          image_tensor=torch.nn.functional.pad(image_array, ((2750-2560),0,0,(3500-3328)))\n",
        "          mask_tensor=torch.nn.functional.pad(mask_array, ((2750-2560),0,0,(3500-3328)))\n",
        "      \n",
        "      return(image_tensor,mask_tensor)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        \n",
        "        # read data\n",
        "        image = pydicom.dcmread(self.images_fps[i])\n",
        "        image = image.pixel_array.astype('float')\n",
        "        image_re = cv2.resize(image,(250,250))\n",
        "        image = torch.from_numpy(image)\n",
        "      \n",
        "        mask = cv2.imread(self.masks_fps[i])\n",
        "        mask_re = cv2.resize(mask,(250,250))\n",
        "        mask_re = torch.from_numpy(mask_re)\n",
        "        mask_re = mask_re.long()\n",
        "        mask_re = abs((mask_re.sum(2)/3)-1)\n",
        "        mask_re = (mask_re>0).float()\n",
        "        mask = torch.from_numpy(mask)\n",
        "        mask = mask.long()\n",
        "        mask = abs((mask.sum(2)/3)-1)\n",
        "        mask = (mask>0).float()\n",
        "\n",
        "        position=self.breast_left_or_right(image)\n",
        "        image_pad, mask_pad = self.image_padding(position,image,mask)\n",
        "\n",
        "        return image_pad, mask_pad, image_re, mask_re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIbydE0wKywB",
        "colab_type": "text"
      },
      "source": [
        "Load train, validation and test dataset from drive that was previously saved so that all trainings/testings are done on exactly the same images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owmmKS2OjMG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loader=(torch.load('/gdrive/My Drive/test_loader.pth'))\n",
        "train_loader=(torch.load('/gdrive/My Drive/train_loader.pth'))\n",
        "val_loader=(torch.load('/gdrive/My Drive/val_loader.pth'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puZtHevRLIKq",
        "colab_type": "text"
      },
      "source": [
        "Add the code for the necessary network \n",
        "Here the standard UNet is used as example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7FWqKRu-swU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
        "        diffX = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "      \n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        self.down4 = Down(512, 512)\n",
        "        self.up1 = Up(1024, 256, bilinear)\n",
        "        self.up2 = Up(512, 128, bilinear)\n",
        "        self.up3 = Up(256, 64, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoylwUfRKsMY",
        "colab_type": "text"
      },
      "source": [
        "Function to calculate IoU, Dice coeff etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTlK8b0BKp4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metrics(predicted,truth,word):\n",
        "  ####### metrics for tumour\n",
        "  TP=0\n",
        "  FN=0\n",
        "  FP=0\n",
        "  TN=0\n",
        "  for i in range(truth.squeeze().size()[0]):\n",
        "    for j in range(truth.squeeze().size()[1]):\n",
        "      if truth[i,j]==1 and predicted[i,j]==1:\n",
        "        TP+=1\n",
        "      elif truth[i,j]==1 and predicted[i,j]==0:\n",
        "        FN+=1\n",
        "      elif truth[i,j]==0 and predicted[i,j]==1:\n",
        "        FP+=1\n",
        "      else:\n",
        "        TN+=1\n",
        "  \n",
        "  if TP==0 and FP==0 and FN==0:\n",
        "    iou_tumour=0\n",
        "    dice_tumour=0\n",
        "  else:\n",
        "    iou_tumour = TP/(TP+FP+FN)\n",
        "    dice_tumour = (2*TP)/(TP+FP+TP+FN)\n",
        "\n",
        "  if TN==0 and FP==0:\n",
        "    spec_tumour=0\n",
        "  else:\n",
        "    spec_tumour = TN/(TN+FP) #specificity #true negative rate\n",
        " \n",
        "  if TP==0 and FN==0:\n",
        "    sens_tumour=0\n",
        "  else:\n",
        "    sens_tumour = TP/(TP+FN) #sensitivity #true positive rate\n",
        "\n",
        "  acc_tumour = (TP+TN)/(TP+TN+FP+FN) #accuracy\n",
        "\n",
        "  ####### metrics for background\n",
        "  truth_b=abs(truth-1)\n",
        "  predicted_b=abs(predicted-1)\n",
        "  TP_b=0\n",
        "  FN_b=0\n",
        "  FP_b=0\n",
        "  TN_b=0\n",
        "  for i in range(truth_b.squeeze().size()[0]):\n",
        "    for j in range(truth_b.squeeze().size()[1]):\n",
        "      if truth_b[i,j]==1 and predicted_b[i,j]==1:\n",
        "        TP_b+=1\n",
        "      elif truth_b[i,j]==1 and predicted_b[i,j]==0:\n",
        "        FN_b+=1\n",
        "      elif truth_b[i,j]==0 and predicted_b[i,j]==1:\n",
        "        FP_b+=1\n",
        "      else:\n",
        "        TN_b+=1\n",
        "  \n",
        "  if TP_b==0 and FP_b==0 and FN_b==0:\n",
        "    iou_background=0\n",
        "    dice_background=0\n",
        "  else:\n",
        "    iou_background = TP_b/(TP_b+FP_b+FN_b)\n",
        "    dice_background = (2*TP_b)/(TP_b+FP_b+TP_b+FN_b)\n",
        "\n",
        "  if TN_b==0 and FP_b==0:\n",
        "    spec_background=0\n",
        "  else:\n",
        "   spec_background = TN_b/(TN_b+FP_b) #specificity #true negative rate\n",
        " \n",
        "  if TP_b==0 and FN_b==0:\n",
        "    sens_background=0\n",
        "  else:\n",
        "    sens_background = TP_b/(TP_b+FN_b) #sensitivity #true positive rate\n",
        "\n",
        "  acc_background = (TP_b+TN_b)/(TP_b+TN_b+FP_b+FN_b) #accuracy\n",
        "\n",
        "  ####### metrics for mean of tumour & background\n",
        "  object_nb=0\n",
        "  if 1 not in truth:\n",
        "    object_nb=1\n",
        "  else:\n",
        "    object_nb=2\n",
        "  \n",
        "  mean_iou=(iou_tumour+iou_background)/object_nb\n",
        "  mean_dice=(dice_tumour+dice_background)/object_nb\n",
        "  mean_spec=(spec_tumour+spec_background)/object_nb\n",
        "  mean_sens=(sens_tumour+sens_background)/object_nb\n",
        "  mean_acc=(acc_tumour+acc_background)/2\n",
        "  \n",
        "  if word=='iou':\n",
        "    return(iou_tumour,iou_background,mean_iou)\n",
        "  elif word=='AllTumour':\n",
        "    return(iou_tumour,dice_tumour,spec_tumour,sens_tumour,acc_tumour)\n",
        "  elif word=='AllBackground':\n",
        "    return(iou_background,dice_background,spec_background,sens_background,acc_background)\n",
        "  elif word=='AllMean':\n",
        "    return(mean_iou,mean_dice,mean_spec,mean_sens,mean_acc)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGXDDL5Cojr9",
        "colab_type": "text"
      },
      "source": [
        "Functions for ROC curve etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5OWyaFSxtac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################### ROC curve and AUC ################################\n",
        "def ROC(iou_tumour_list,ground):\n",
        "  prediction=[]\n",
        "  threshold=0.1\n",
        "  for i in range(len(iou_tumour_list)):\n",
        "    if iou_tumour_list[i]<threshold:\n",
        "      prediction.append(0)\n",
        "    else:\n",
        "      prediction.append(1)\n",
        "\n",
        "  fpr, tpr, thresholds = roc_curve(ground, prediction, pos_label=1)\n",
        "  AUC = roc_auc_score(fpr, tpr)\n",
        "\n",
        "  fig=plt.figure()\n",
        "  plt.plot(fpr, tpr, color='orange', label='ROC')\n",
        "  plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  fig.savefig('/gdrive/My Drive'+path+name+'_ROC_curve.png')\n",
        "\n",
        "  return(AUC)\n",
        "\n",
        "#################### Precision-Recall Curve, F1 score & AUPRC ################################\n",
        "def Recall_Precision(iou_tumour_list,ground):\n",
        "  precision, recall, thresholds = precision_recall_curve(ground, iou_tumour_list)\n",
        "  no_skill = len(ground[ground==1]) / len(ground)\n",
        "  fig=plt.figure()\n",
        "  plt.plot([0, 1], [no_skill, no_skill], linestyle='--')\n",
        "  plt.plot(recall, precision, marker='.', label='Logistic')\n",
        "  plt.xlabel('Recall')\n",
        "  plt.ylabel('Precision')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  fig.savefig('/gdrive/My Drive'+path+name+'_RecallPrecision_curve.png')\n",
        "\n",
        "  prediction=[]\n",
        "  for i in range(len(iou_tumour_list)):\n",
        "    if iou_tumour_list[i]<threshold:\n",
        "      prediction.append(0)\n",
        "    else:\n",
        "      prediction.append(1)\n",
        "\n",
        "  f1 = f1_score(ground, prediction, pos_label=1)\n",
        "  auprc = auc(recall, precision)\n",
        "\n",
        "  return(f1, auprc)\n",
        "\n",
        "#################### Accuracy ################################\n",
        "def AccuracyGraph(iou_list,val_list):\n",
        "  f, (ax1) = plt.subplots(1, 1, figsize=(7, 4))\n",
        "  epoch_list = list(range(0,30))\n",
        "  ax1.plot(epoch_list, iou_list, label='Train Accuracy')\n",
        "  ax1.plot(epoch_list, val_iou_list, label='Validation Accuracy')\n",
        "  ax1.set_xticks(np.arange(0, 30, 1))\n",
        "  ax1.set_ylabel('Accuracy Value')\n",
        "  ax1.set_xlabel('Epoch')\n",
        "  ax1.set_title('Accuracy')\n",
        "  l1 = ax1.legend(loc=\"best\")\n",
        "  ax1.figure.savefig('/gdrive/My Drive/'+path+name+'_AccuracyGraph.png')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP20S-MUYeoq",
        "colab_type": "text"
      },
      "source": [
        "Model: link the path to the network that has been pre-trained with on one of the two patch extracted database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbJ1GnPWBbmq",
        "colab_type": "code",
        "outputId": "79bd4ed1-964d-4bca-bcef-38b8b1e96b87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "path_transfer='/networks/FULL_TRANSFER/UNet_WholeMass_full/'\n",
        "name_transfer='UNet_WholeMass_full'\n",
        "model = UNet(n_classes=2, n_channels=1)\n",
        "model.load_state_dict(torch.load('/gdrive/My Drive/'+path_transfer+name_transfer+'.pth'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svKht0GzYg_i",
        "colab_type": "text"
      },
      "source": [
        "Optimizer & criterion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F2zPbjDBe3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss() \n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HH0Q44xf0oa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path='/networks/FULL_TRANSFER/UNet_WholeMass_full/'\n",
        "name='UNet_WholeMass_full'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g0gYNG0Kmus",
        "colab_type": "text"
      },
      "source": [
        "Training: Wieght Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYXJ4eItO3f_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=20\n",
        "best=0\n",
        "best_tumour=0.0\n",
        "train_iou = 0.0\n",
        "val_iou = 0.0\n",
        "val_tumour_iou=[]\n",
        "counter=0\n",
        "iou_list=[]\n",
        "val_iou_list=[]\n",
        "nb_patches_analyzed=0\n",
        "nb_patches_analyzed_v=0\n",
        "\n",
        "file = open('/gdrive/My Drive'+path+'training.txt','w')\n",
        "file.write('Training: 20 epochs full transfer from 1connected patches\\n')\n",
        "\n",
        "time.sleep(5)\n",
        "for epoch in range(epochs):  \n",
        "\n",
        "    ###################### Training\n",
        "    time.sleep(5)\n",
        "    Bar = progressbar.ProgressBar(max_value=len(train_loader))\n",
        "    for i, data in enumerate(Bar(train_loader), 0):\n",
        "        image, mask, image_re, mask_re = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(image_re.unsqueeze(dim=0).float()) \n",
        "        outputs_final_probabilities, outputs_final = torch.max(outputs.squeeze(), axis=0) \n",
        "        loss = criterion(outputs.float(), mask_re.long())\n",
        "        loss.backward() #backward propagation\n",
        "        optimizer.step() #optimize\n",
        "        iou_tumour,iou_background,mean_iou = metrics(outputs_final,mask_re.squeeze(),'iou')\n",
        "        train_iou+=mean_iou\n",
        "\n",
        "    ############### Validation\n",
        "    time.sleep(5)\n",
        "    BarTwo = progressbar.ProgressBar(max_value=len(val_loader))   \n",
        "    for i, data_v in enumerate(BarTwo(val_loader), 0):\n",
        "        image_v, mask_v, image_re_v, mask_re_v = data_v\n",
        "        outputs_v=model(image_re_v.unsqueeze(dim=0).float())\n",
        "        outputs_final_probabilities_v, outputs_final_v = torch.max(outputs_v.squeeze(), axis=0)\n",
        "        iou_tumour,iou_background,mean_iou = metrics(outputs_final_v,mask_re_v.squeeze(),'iou')\n",
        "        val_iou+=mean_iou\n",
        "        if 1 in mask_re_v:\n",
        "          val_tumour_iou.append(iou_tumour)\n",
        "\n",
        "\n",
        "    ################ save best model\n",
        "    if val_iou > best:\n",
        "      best=val_iou\n",
        "      torch.save(model.state_dict(),'/gdrive/My Drive/'+path+name+'.pth')\n",
        "    \n",
        "    if sum(val_tumour_iou) > best_tumour:\n",
        "      best_tumour=sum(val_tumour_iou)\n",
        "      torch.save(model.state_dict(),'/gdrive/My Drive/'+path+name+'_tumour.pth')\n",
        "      \n",
        "    ################ print for each epoch iou\n",
        "    print('Epoch %d :iou train: %.3f' % (epoch + 1, train_iou/ len(train_loader)),'; iou val: %.3f' % (val_iou/ len(val_loader)),'; tumour iou val: %.3f' % (sum(val_tumour_iou)/ len(val_tumour_iou)),'\\n')\n",
        "    file.write('\\n\\nEpoch %d : mean iou train: %.3f' % (epoch + 1, train_iou/ len(train_loader)))\n",
        "    file.write(' ;mean iou validation: %.3f' % (val_iou/ len(val_loader)))  \n",
        "    file.write(' ;tumour iou validation: %.3f' % (sum(val_tumour_iou)/ len(val_tumour_iou)))     \n",
        "\n",
        "    iou_list.append(train_iou/ len(train_loader))\n",
        "    val_iou_list.append(val_iou/ len(val_loader))\n",
        "\n",
        "    #print for every 20 epoch\n",
        "    if (counter%1)==0:\n",
        "      fig = plt.figure()\n",
        "      plt.subplot(1, 3, 1)\n",
        "      plt.imshow(image_re.squeeze())\n",
        "      plt.subplot(1, 3, 2)\n",
        "      plt.imshow(mask_re.squeeze())\n",
        "      plt.subplot(1, 3, 3)\n",
        "      plt.imshow(outputs_final.detach().numpy())\n",
        "\n",
        "    counter+=1\n",
        "    train_iou = 0.0\n",
        "    val_tumour_iou = []\n",
        "    nb_patches_analyzed=0\n",
        "    nb_patches_analyzed_v=0\n",
        "    val_iou=0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# file.write('\\n\\nTrain iou list')\n",
        "# file.wirte(iou_list)\n",
        "# file.write('Validation iou_list')\n",
        "# file.write(val_iou_list)\n",
        "file.close()\n",
        "\n",
        "# AccuracyGraph(iou_list,val_iou_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-R_d9DSYvfuc",
        "colab_type": "text"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmeGHUoENQZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(torch.load('/gdrive/My Drive/'+path+name+'.pth'))\n",
        "\n",
        "file = open('/gdrive/My Drive'+path+'testing.txt','w')\n",
        "file.write('Testing \\n')\n",
        "\n",
        "iou_tumour_list=[] #iou_tumour_list: for each of the 28 images, this list contains the corresponding iou value\n",
        "ground=[] #ground: for each of the 28 image analzed, 1 correspond to images with a tumour\n",
        "test_iou = 0.0\n",
        "test_dice = 0.0\n",
        "test_spec = 0.0\n",
        "test_sens = 0.0\n",
        "test_acc = 0.0\n",
        "test_iou_tumour = 0.0\n",
        "test_dice_tumour = 0.0\n",
        "test_spec_tumour = 0.0\n",
        "test_sens_tumour = 0.0\n",
        "test_acc_tumour = 0.0\n",
        "\n",
        "false_positive=0\n",
        "true_positive=0\n",
        "false_negative=0\n",
        "true_negative=0\n",
        "FPR=0\n",
        "TPR=0\n",
        "FNR=0\n",
        "TNR=0\n",
        "tum_count=0\n",
        "\n",
        "################ test model\n",
        "for i, data_t in enumerate(test_loader, 0):\n",
        "  image_t, mask_t, image_re_t, mask_re_t = data_t\n",
        "  outputs_t=model(image_re_t.unsqueeze(dim=0).float())\n",
        "  outputs_final_probabilities_t, outputs_final_t = torch.max(outputs_t.squeeze(), axis=0)\n",
        "  iou_tumour,iou_background,mean_iou = metrics(outputs_final_t,mask_re_t.squeeze(),'iou')\n",
        "  test_iou += mean_iou \n",
        "  mean_iou,mean_dice,mean_spec,mean_sens,mean_acc= metrics(outputs_final_t,mask_re_t.squeeze(),'AllMean')\n",
        "  test_dice += mean_dice\n",
        "  test_spec += mean_spec\n",
        "  test_sens += mean_sens\n",
        "  test_acc += mean_acc\n",
        "  iou_tumour_list.append(iou_tumour)\n",
        "  print('\\n\\nTest Image %d : Mean iou %.3f' % (i+1, mean_iou))\n",
        "  file.write('\\n\\nTest image %d : Mean iou %.3f, mean dice %.3f, mean spec %.3f, mean sens %.3f, mean acc %.3f' % (i+1,mean_iou,mean_dice,mean_spec,mean_sens,mean_acc))\n",
        "\n",
        "  if 1 in mask_re_t:\n",
        "    print('Tumour Iou: %.3f' % (iou_tumour))\n",
        "    iou_tumour,dice_tumour,spec_tumour,sens_tumour,acc_tumour = metrics(outputs_final_t,mask_re_t.squeeze(),'AllTumour')\n",
        "    test_iou_tumour += iou_tumour\n",
        "    test_dice_tumour += dice_tumour\n",
        "    test_spec_tumour += spec_tumour\n",
        "    test_sens_tumour += sens_tumour\n",
        "    test_acc_tumour += acc_tumour\n",
        "    tum_count+=1\n",
        "    file.write('\\n tumour iou %.3f, tumour dice %.3f, tumour spec %.3f, tumour sens %.3f, tumour acc %.3f' % (iou_tumour,dice_tumour,spec_tumour,sens_tumour,acc_tumour))\n",
        "\n",
        "  if 1 in mask_re_t:\n",
        "    ground.append(1)\n",
        "  else:\n",
        "    ground.append(0)\n",
        "\n",
        "  if 1 in mask_re_t.squeeze() and 1 in outputs_final_t.squeeze():\n",
        "    true_positive=true_positive+1\n",
        "  elif 1 not in mask_re_t.squeeze() and 1 in outputs_final_t.squeeze():\n",
        "    false_positive=false_positive+1\n",
        "  elif 1 in mask_re_t.squeeze() and 1 not in outputs_final_t.squeeze():\n",
        "    false_negative=false_negative+1\n",
        "  else:\n",
        "    true_negative=true_negative+1\n",
        "\n",
        "  fig = plt.figure()\n",
        "  plt.subplot(1, 3, 1)\n",
        "  plt.imshow(image_re_t.squeeze())\n",
        "  plt.subplot(1, 3, 2)\n",
        "  plt.imshow(mask_re_t.squeeze())\n",
        "  plt.subplot(1, 3, 3)\n",
        "  plt.imshow(outputs_final_t.detach().numpy())\n",
        "  matplotlib.image.imsave('/gdrive/My Drive'+path+'test2/'+name+'_image_'+str(i)+'.png',image_t.squeeze())\n",
        "  matplotlib.image.imsave('/gdrive/My Drive'+path+'test2/'+name+'_mask_'+str(i)+'.png',mask_t.squeeze())\n",
        "  matplotlib.image.imsave('/gdrive/My Drive'+path+'test2/'+name+'_prediction_'+str(i)+'.png',outputs_final_t.detach().numpy())\n",
        "\n",
        "\n",
        "#print('\\nOverall Test Images: test loss: %.3f' % (test_loss / len(test_loader)))\n",
        "print('\\n\\n\\nOver entire Test data set: average mean iou: %.3f' % (test_iou/ len(test_loader)))\n",
        "file.write('\\n\\n\\n\\nOverall iou %.3f, overall dice %.3f, overall spec %.3f, overall sens %.3f, overall acc %.3f' % (test_iou/len(test_loader),test_dice/len(test_loader),test_spec/len(test_loader),test_sens/len(test_loader),test_acc/len(test_loader)))\n",
        "print('\\nAverage tumour iou (for mask that have tumour): %.3f' % (test_iou_tumour/tum_count), '\\n')\n",
        "file.write('\\n\\nOverall tumour iou %.3f, overall tumour dice %.3f, overall tumour spec %.3f, overall tumour sens %.3f, tumour overall acc %.3f' % (test_iou_tumour/tum_count,test_dice_tumour/tum_count,test_spec_tumour/tum_count,test_sens_tumour/tum_count,test_acc_tumour/tum_count))\n",
        "\n",
        "####### from testing\n",
        "FPR=false_positive/(false_positive+true_negative) #False Positive Rate \n",
        "TPR=true_positive/(true_positive+false_negative) #True Positive Rate ###Sens\n",
        "FNR=false_negative/(false_negative+true_positive) #False Negative Rate\n",
        "TNR=true_negative/(true_negative+false_positive) #True Negative Rate ###Spec\n",
        "\n",
        "Acc=(true_negative+true_positive)/(false_positive+false_negative+true_negative+true_positive)\n",
        "\n",
        "auc=ROC(iou_tumour_list,ground)\n",
        "\n",
        "# f1, auprc = Recall_Precision(iou_tumour_list,ground)\n",
        "\n",
        "# file.write('\\n\\n-------------------')\n",
        "# file.write('\\nAUC: ')\n",
        "# file.write(auc)\n",
        "# file.write('\\nF1: ',f1,' ;AUPRC: ',auprc)\n",
        "file.close()\n",
        "\n",
        "# print('False Positive Rate:', FPR, '\\n')\n",
        "# print('True Positive Rate:', TPR, '\\n')\n",
        "# print('False Negative Rate:', FNR, '\\n')\n",
        "# print('True Negative Rate:', TNR, '\\n')\n",
        "# print('Acc:', acc, '\\n')\n",
        "# print('AUC:', auc, '\\n')\n",
        "# print('F1:', f1, 'AUPRC:', auprc, '\\n')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsjTo_KT6K8y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
