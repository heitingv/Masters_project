# -*- coding: utf-8 -*-
"""original_unet_10_epochs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_xsod-c83R38oo14SBdM7wUXe4q-uvUY
"""

!pip install pydicom
!pip install barbar

from google.colab import drive
drive.mount('/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /gdrive/My\ Drive

import os
import matplotlib
import numpy as np
import cv2
import matplotlib.pyplot as plt
import pydicom
from tqdm import tqdm_notebook as tqdm

import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.autograd import Variable
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torch.utils.data import Dataset as BaseDataset
from tqdm import trange
from time import sleep
from torch.utils.data.sampler import SubsetRandomSampler 
use_gpu = torch.cuda.is_available()

class Dataset(BaseDataset):

    CLASSES = ['non tumor','tumor']

    def __init__(self, images_dir, masks_dir, classes=None):
        self.ids_f=[]
        self.ids_m_f=[]
        self.ids = os.listdir(images_dir)
        self.ids_m = os.listdir(masks_dir)
        for i in range(len(self.ids)):
          self.ids[i]=self.ids[i].rstrip(".dcm")
          for i in range(len(self.ids_m)):
            self.ids_m[i]=self.ids_m[i].rstrip(".png")

        for temp in self.ids_m:
          if temp in self.ids:
            self.ids_f.append(temp+'.dcm')
            self.ids_m_f.append(temp+'.png')

        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids_f]
        self.masks_fps = [os.path.join(masks_dir, mask_id) for mask_id in self.ids_m_f]
        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]
        
        # convert str names to class values on masks
        # self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]
    
    def __len__(self):
        return len(self.ids_f)

    def __getitem__(self, i):
        
        # read data
        image = pydicom.dcmread(self.images_fps[i])
        image = image.pixel_array.astype('float')
        image = cv2.resize(image,(256,256))
        image = torch.from_numpy(image)
        # image = image.unsqueeze(0)
      
        mask = cv2.imread(self.masks_fps[i])
        #mask = mask.pixel_array.astype('float')
        mask = cv2.resize(mask,(256,256))
        mask = torch.from_numpy(mask)
        mask=mask.long()
        mask=abs((mask.sum(2)/3)-1)
        mask = (mask>0).float()
        
        return image, mask,

class Dataset_with_NonMass(BaseDataset): #original data non padded or changed in size 

    CLASSES = ['non tumor','tumor']

    def __init__(self, images_dir, masks_dir, classes=None):
        self.ids_f=[]
        self.ids_m_f=[]
        self.ids = os.listdir(images_dir)
        self.ids_m = os.listdir(masks_dir)
        self.images_fps=[]
        self.masks_fps=[]
        for i in range(len(self.ids)):
          self.ids[i]=self.ids[i].rstrip(".dcm")
          for i in range(len(self.ids_m)):
            self.ids_m[i]=self.ids_m[i].rstrip(".png")

        for i in range(len(self.ids)):
          temp=self.ids[i][0:8]
          if temp in self.ids_m:
            self.ids_f.append(self.ids[i]+'.dcm')
            self.ids_m_f.append(temp+'.png')

        for i in range(len(self.ids_m_f)):
          mask_id=self.ids_m_f[i]
          image_id=self.ids_f[i]
          temp=os.path.join(masks_dir, mask_id)
          presence=self.test_mass(temp)

          if presence==False:
            self.images_fps.append(os.path.join(images_dir, image_id))
            self.masks_fps.append(os.path.join(masks_dir, mask_id))

          temp=None
          mask_id=None
          image_id=None

        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]

    def test_mass(self,name):
      presence=None

      mask = cv2.imread(name)
      mask = torch.from_numpy(mask)
      mask=mask.long()
      mask=abs((mask.sum(2)/3)-1)
      mask = (mask>0).float()

      if 1 in mask:
        presence=True
      else:
        presence=False

      return(presence)


    def __len__(self):
        return len(self.images_fps)

    def __getitem__(self, i):
        
        # read data
        image = pydicom.dcmread(self.images_fps[i])
        image = image.pixel_array.astype('float')
        image = cv2.resize(image,(256,256))
        image = torch.from_numpy(image)
      
        mask = cv2.imread(self.masks_fps[i])
        mask = cv2.resize(mask,(256,256))
        mask = torch.from_numpy(mask)
        mask = mask.long()
        mask = abs((mask.sum(2)/3)-1)
        mask = (mask>0).float()

        return image, mask

full_dataset = Dataset('/gdrive/My Drive/mass','/gdrive/My Drive/mask', classes=['non tumor','tumor'])
num_train=len(full_dataset)

size_train= int(np.ceil(0.6* num_train))
size_val= int(np.floor(0.2* num_train))
size_test= int(np.floor(0.2* num_train))

train_set, val_set, test_set = torch.utils.data.random_split(full_dataset, [size_train, size_val, size_test])

dataset_NonMass = Dataset_with_NonMass('/gdrive/My Drive/AllDICOMs','/gdrive/My Drive/total', classes=['non tumor','tumor'] )

#need same amount for training mass & non mass
nb_NonMass_images_trained=int(np.ceil(0.3*(size_train))) #add 30% more images that don't have mass 
nb_NonMass_images_validation=int(np.ceil(0.3*(size_val))) #add 30% more images that don't have mass
nb_NonMass_images_tested=int(np.ceil(0.3*(size_test))) #add 30% more images that don't have mass

NonMass_set_train,NonMass_set_val,NonMass_set_test, unwanted_set = torch.utils.data.random_split(dataset_NonMass, [nb_NonMass_images_trained,nb_NonMass_images_validation,nb_NonMass_images_tested,len(dataset_NonMass)-(nb_NonMass_images_trained+nb_NonMass_images_validation+nb_NonMass_images_tested)])
full_train_loader = torch.utils.data.ConcatDataset([train_set,NonMass_set_train])
full_val_loader = torch.utils.data.ConcatDataset([val_set,NonMass_set_val])
full_test_loader = torch.utils.data.ConcatDataset([test_set,NonMass_set_test])

train_loader = torch.utils.data.DataLoader(full_train_loader,shuffle=True,batch_size=1)
val_loader = torch.utils.data.DataLoader(full_val_loader,shuffle=True,batch_size=1)
test_loader = torch.utils.data.DataLoader(full_test_loader,shuffle=True,batch_size=1)

torch.save(test_loader, '/gdrive/My Drive/test_loader_original_unet.pth') 
torch.save(train_loader, '/gdrive/My Drive/train_loader_original_unet.pth') 
torch.save(val_loader, '/gdrive/My Drive/val_loader_original_unet.pth')

class DoubleConv(nn.Module):
    """(convolution => [BN] => ReLU) * 2"""

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.double_conv(x)


class Down(nn.Module):
    """Downscaling with maxpool then double conv"""

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.maxpool_conv = nn.Sequential(
            nn.MaxPool2d(2),
            DoubleConv(in_channels, out_channels)
        )

    def forward(self, x):
        return self.maxpool_conv(x)


class Up(nn.Module):
    """Upscaling then double conv"""

    def __init__(self, in_channels, out_channels, bilinear=True):
        super().__init__()

        # if bilinear, use the normal convolutions to reduce the number of channels
        if bilinear:
            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
        else:
            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)

        self.conv = DoubleConv(in_channels, out_channels)

    def forward(self, x1, x2):
        x1 = self.up(x1)
        # input is CHW
        diffY = torch.tensor([x2.size()[2] - x1.size()[2]])
        diffX = torch.tensor([x2.size()[3] - x1.size()[3]])

        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,
                        diffY // 2, diffY - diffY // 2])
        # if you have padding issues, see
        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a
        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd
        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)


class OutConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(OutConv, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)

    def forward(self, x):
        return self.conv(x)

class UNet(nn.Module):
    def __init__(self, n_channels, n_classes, bilinear=True):
        super(UNet, self).__init__()
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.bilinear = bilinear

        self.inc = DoubleConv(n_channels, 64)
        self.down1 = Down(64, 128)
        self.down2 = Down(128, 256)
        self.down3 = Down(256, 512)
        self.down4 = Down(512, 512)
        self.up1 = Up(1024, 256, bilinear)
        self.up2 = Up(512, 128, bilinear)
        self.up3 = Up(256, 64, bilinear)
        self.up4 = Up(128, 64, bilinear)
        self.outc = OutConv(64, n_classes)

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)
        x = self.up1(x5, x4)
        x = self.up2(x, x3)
        x = self.up3(x, x2)
        x = self.up4(x, x1)
        logits = self.outc(x)
        return logits

unet = UNet(n_classes=2, n_channels=1)

import torch.optim as optim

criterion = nn.CrossEntropyLoss() 
optimizer = optim.SGD(unet.parameters(), lr=0.001, momentum=0.9)

def iou(predicted,truth): #truth=mask and predicted=outputs_final
    # But if you are passing output from UNet or something it will most probably
    # be with the BATCH x 1 x H x W shape
  
    overlap_tumour = (truth*predicted).sum()  # Will be zero if Truth=0 or Prediction=0
    union_tumour = (predicted+truth)
    union_tumour = (union_tumour>0).float()        #transform numbers >1 to 1
    union_tumour = union_tumour.sum()
    
    if overlap_tumour==0 or union_tumour==0:
      iou_tumour=0
    else:
      iou_tumour = overlap_tumour / union_tumour

    truth_b=abs(truth-1)
    predicted_b=abs(predicted-1)    
    overlap_background = (truth_b*predicted_b).sum()  # Will be zero if Truth=0 or Prediction=0
    union_background = (predicted_b+truth_b)
    union_background = (union_background>0).float()
    union_background = union_background.sum()
   
    if overlap_background==0 or union_background==0:
      iou_background=0
    else:
      iou_background = overlap_background / union_background
   
    iou_background = (overlap_background + 0.00000001) / (union_background + 0.00000001)

    #thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10  # This is equal to comparing with thresolds
    
    iou_t=(iou_tumour+iou_background)/2

    iou=iou_t.item()

    return iou

def iou_tumour(predicted,truth): #truth=mask and predicted=outputs_final
    # But if you are passing output from UNet or something it will most probably
    # be with the BATCH x 1 x H x W shape
  
    overlap_tumour = (truth*predicted).sum()  # Will be zero if Truth=0 or Prediction=0
    union_tumour = (predicted+truth)
    union_tumour = (union_tumour>0).float()        #transform numbers >1 to 1
    union_tumour = union_tumour.sum()
    
    if overlap_tumour==0 or union_tumour==0:
      iou_tumour=0.0
    else:
      iou_tumour = overlap_tumour / union_tumour
      iou_tumour = iou_tumour.item()

    return iou_tumour

running_loss = 0.0
epochs=10
print_every=1
val_loss = 0.0
best_loss=0.0
iou_loss = 0.0
val_iou_loss = 0.0
counter=0

import time
from barbar import Bar 
import progressbar
from sklearn import metrics
from sklearn.metrics import roc_curve

model_p=unet
#model_p.load_state_dict(torch.load('/gdrive/My Drive/model_patch.pth'))

time.sleep(5)
for epoch in range(epochs):  # loop over the dataset multiple times

    time.sleep(5)
    Bar = progressbar.ProgressBar(max_value=len(train_loader))
    #train 
    for i, data in enumerate(Bar(train_loader), 0):
        image, mask = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = model_p(image.unsqueeze(dim=0).float()) #forward propagation # outputs = [batch_size, nb_class=2, H=256, W=256]
        image = image.squeeze() # image = [H=256, W=256]
        #mask = mask.squeeze(0) # mask = [batch_size, H=256, W=256]
        outputs_final_probabilities, outputs_final = torch.max(outputs.squeeze(), axis=0) #takes the maximum probability either background or tumour
        #outputs_final_probabilites takes maximum probabilities between background or tumour
        #outputs_final is the array with the two classe, only with value of one or zero; predicted image
        #outputs_final = torch.tensor(outputs_final.float(),requires_grad=True)
        loss = criterion(outputs.float(), mask.long())
        loss.backward() #backward propagation
        optimizer.step() #optimize
        running_loss += loss.item()
        iou_loss += iou(outputs_final,mask.squeeze()) #look at the loss info cad correct or not between predicted output and real class/label
       
    time.sleep(5)
    BarTwo = progressbar.ProgressBar(max_value=len(val_loader))
    #validation     
    for i, data_v in enumerate(BarTwo(val_loader), 0):
        image_v, mask_v = data_v
        outputs_v=model_p(image_v.unsqueeze(dim=0).float())
        image_v = image_v.squeeze()
        #mask_v = mask_v.squeeze(0)
        outputs_final_probabilities_v, outputs_final_v = torch.max(outputs_v.squeeze(), axis=0)
        loss_v = criterion(outputs_v.float(),mask_v.long()) #why in loop because won't change loss 
        val_loss += loss_v.item()
        val_iou_loss += iou(outputs_final_v, mask_v.squeeze()) #look at the loss info cad correct or not between predicted output and real class/label

    #save best model
    if val_iou_loss > best_loss:
      best_loss=val_iou_loss
      torch.save(unet.state_dict(),'/gdrive/My Drive/unet_original_10_epochs.pth')
      
    #print for each epoch #print iou in training and validation
    print('\nEpoch %d : train loss: %.3f' % (epoch + 1, running_loss / len(train_loader)),'; val loss: %.3f' % (val_loss / len(val_loader)))
    print('Epoch %d :iou train loss: %.3f' % (epoch + 1, iou_loss/ len(train_loader)),'; iou val loss: %.3f' % (val_iou_loss/ len(val_loader)),'\n')  

    counter+=1

    #print for every 20 epoch
    if (counter%1)==0:
      fig = plt.figure()
      plt.subplot(1, 3, 1)
      plt.imshow(image)
      plt.subplot(1, 3, 2)
      plt.imshow(mask.squeeze())
      plt.subplot(1, 3, 3)
      plt.imshow(outputs_final.detach().numpy())
      matplotlib.image.imsave('/gdrive/My Drive/images_report/unet_10_original/training/image_patch_epoch_'+str(epoch)+'.png',image.squeeze())
      matplotlib.image.imsave('/gdrive/My Drive/images_report/unet_10_original/training/mask_patch_epoch_'+str(epoch)+'.png',mask.squeeze())
      matplotlib.image.imsave('/gdrive/My Drive/images_report/unet_10_original/training/prediction_patch_epoch_'+str(epoch)+'.png',outputs_final.detach().numpy())

    val_loss = 0.0
    running_loss = 0.0
    iou_loss = 0.0
    val_iou_loss = 0.0

print('Finished Training')

model=unet
model.load_state_dict(torch.load('/gdrive/My Drive/unet_original_10_epochs_with_NonMassImages.pth'))
test_loss = 0.0
test_iou_loss = 0.0
iou_tumour_list=[]
ground=[]

#time.sleep(2)
#test model
for i, data_t in enumerate(test_loader, 0):
  #BarTest = progressbar.ProgressBar(max_value=1)
  #time.sleep(2)
  image_t, mask_t = data_t
  outputs_t=model(image_t.unsqueeze(dim=0).float())
  image_t = image_t.squeeze()
  #mask_v = mask_v.squeeze(0)
  outputs_final_probabilities_t, outputs_final_t = torch.max(outputs_t.squeeze(), axis=0)
  loss_t = criterion(outputs_t.float(),mask_t.long()).item() #why in loop because won't change loss 
  test_loss += loss_t
  iou_single = iou(outputs_final_t, mask_t.squeeze()) #mean iou
  iou_tumour_list.append((iou_tumour(outputs_final_t, mask_t.squeeze())))
  test_iou_loss += iou_single 

  if 1 in mask_t:
    ground.append(1)
  else:
    ground.append(0)

#iou_tumour_list: for each of the 28 images, this list contains the corresponding iou value
#ground: for each of the 28 image analzed, 1 correspond to images with a tumour

  #print for each epoch #print iou in training and validation
  print('\nTest Image %d : test loss: %.3f' % (i + 1, loss_t))
  print('Test Image %d : mean iou: %.3f' % (i + 1, iou_single),'\n')  

  fig = plt.figure()
  plt.subplot(1, 3, 1)
  plt.imshow(image_t)
  plt.subplot(1, 3, 2)
  plt.imshow(mask_t.squeeze())
  plt.subplot(1, 3, 3)
  plt.imshow(outputs_final_t.detach().numpy())

#print('\nOverall Test Images: test loss: %.3f' % (test_loss / len(test_loader)))
print('Overall Test Images: mean iou: %.3f' % (test_iou_loss/ len(test_loader)),'\n')

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

prediction=[]
threshold=0.1
true_positive=[]
false_positive=[]
true_negative=[]
false_negative=[]

# print(ground)
# print(iou_tumour_list)

for i in range(len(iou_tumour_list)):
  if iou_tumour_list[i]<threshold:
    prediction.append(0)
  else:
    prediction.append(1)

fpr, tpr, thresholds = roc_curve(ground, prediction, pos_label=1)

plt.plot(fpr, tpr, color='orange', label='ROC')
plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()
plt.show()

print(thresh)

print(ground.shape())

print(prediction)

print(tpr)

print(iou_tumour_list)

"""get ROC curves, these have oredicted someone, but was there 
iou threshold to 0.1,0.2
if detection is false positive, false negative or true etc...
"""